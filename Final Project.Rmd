---
title: "STAC67 Final Project Report"
author: "Nilson Gao, Vedat Goktepe, Rebecca Han, Ben Wang"
date: "2024-12-03"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

[TO DO: make this in title page as required by rubric]

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(leaps)
library(ggplot2)
library(gridExtra)
library(patchwork)
library(ggcorrplot)
library(car)
library(MASS)
```

# Research Context

The objective of this model is to investigate the intrinsic factors that affect Price of Cars in Serbia based off detailed car listings provided by an online marketplace where [TO DO - yap about car price significance, what question we want to answer, how this can be beneficial knowledge for consumers/dealerships/car companies/manufacturers/etc.]

# Exploratory Data Analysis

```{r}
# read data file, published in 2024 on https://www.kaggle.com/datasets/mmakarovlab/serbia-car-sales-prices?resource=download
car_price_data <- read.csv("serbia_car_sales_price_2024.csv")

```

Before we begin investigating, we notice that there are some issues with the data. Some rows are missing values under certain variables (i.e. #2, #233, #1705, etc.), and some variables are hard to work with. Knowing a car's **year** might be less informative than knowing its age, so we made a new column containing values for $2024-\text{Year}$ called **age**. A car's **horsepower** is significant, but it's hard to use that data when it's given as two values in the format $HP\ (kW)$, so we keep only the HP metric. Additionally, some variable names are hard to work with because of length or how it might interfere with R code, such as **car_mileage, km**, so we made those easier to process as well. As for the missing values, when we analyze the significance of a variable, we'll make sure to exclude rows where values for that variable are empty.

```{r}
clean_data <- car_price_data
clean_data[clean_data == ""] <- NA
clean_data <- na.omit(clean_data)

clean_data$age <- 2024 - clean_data$year
clean_data$horsepower<-gsub(pattern = "^(\\d+) HP.*", replacement = "\\1", clean_data$horsepower)
clean_data$horsepower<-as.numeric(clean_data$horsepower)

# making the variable names easier to process
names(clean_data) <- gsub(pattern = "\\.\\..*", replacement = "", names(clean_data))

#will keep this here
summary(clean_data)
```

Now, we want to check on which variables are good predictors. For the continuous variables, we first plot scatter graphs for each variable against car price:

```{r}
p1 <- ggplot(clean_data, aes(x = age, y = price)) + geom_point() + theme_minimal() + ggtitle("age vs price")
p2 <- ggplot(clean_data, aes(x = horsepower, y = price)) + geom_point() + theme_minimal() + ggtitle("horsepower vs price")
p3 <- ggplot(clean_data, aes(x = car_mileage, y = price)) + geom_point() + theme_minimal() + ggtitle("car_mileage vs price") # needs outlier removed
p4 <- ggplot(clean_data, aes(x = engine_capacity, y = price)) + geom_point() + theme_minimal() + ggtitle("engine_capacity vs price")
grid.arrange(p1,p2,p3,p4,ncol=2)
```

We notice that there are some influential points (and possibly leverage points) on the car_mileage predictor. Let's get rid of those using hat values and semistudentized residuals to detect which ones are too high:

THIS MAY NEED TRIMMING BUT IDK - Nilson

```{r}
outlier_clean <- function(data, model) {
  #removal of points in x (leverage points)
  leverage <- hatvalues(model)
  threshold <- 2* length(coef(model)) / nrow(data)
  leverage_points <- which(leverage > threshold | leverage > 0.5)
  clean <- data[-leverage_points,]
  
  n <- nrow(data)
  threshold <- qt(1 - (0.05/(2*n)), n-2-1)
  semistudentized_residuals <- rstandard(model)
  outlier_points <- which(abs(semistudentized_residuals) > threshold)
  clean <- clean[-outlier_points,]
  
  cooks_d <- cooks.distance(model)
  cooks_threshold <- 4/n #might need to change
  influential_points <- which(cooks_d > cooks_threshold)
  clean <- clean[-influential_points,]
  return(clean)
}

cm_model <- lm(price ~ car_mileage, data = clean_data)
clean_cm <- outlier_clean(clean_data,cm_model)

hp_model <- lm(price ~ horsepower, data = clean_data)
clean_hp <- outlier_clean(clean_data, hp_model)

age_model <- lm(price ~ age, data = clean_data)
clean_age <- outlier_clean(clean_data, age_model)

ec_model <- lm(price ~ engine_capacity, data = clean_data)
clean_ec <- outlier_clean(clean_data, ec_model)

ggplot(clean_cm, aes(x = car_mileage, y = price)) + geom_point() + theme_minimal() + ggtitle("car_mileage vs price") 
ggplot(clean_hp, aes(x = horsepower, y = price)) + geom_point() + theme_minimal() + ggtitle("horsepower vs price")
ggplot(clean_age, aes(x = age, y = price)) + geom_point() + theme_minimal() + ggtitle("age vs price")
ggplot(clean_ec, aes(x = engine_capacity, y = price)) + geom_point() + theme_minimal() + ggtitle("engine_capacity vs price")
```

```{r}
#cleaning for car mileage
model <- lm(price ~ car_mileage, data = clean_data)

# leverage points (outliers in x) removal
leverage <- hatvalues(model)
threshold <- 2 * length(coef(model)) / nrow(clean_data)
leverage_points <- which(leverage > threshold | leverage > 0.5)
clean_cm_data <- clean_data[-leverage_points, ] # clean_cm_data filters out for car_mileage ONLY. This way we can still do comprehensive analysis on other predictors

clean_cm_data <- subset(clean_cm_data, car_mileage <= 750000) # trimming x-axis data, will cause bias. note: 84(?) values removed

# outliers in y removal
n <- nrow(clean_data)
print(n)
threshold <- qt(1 - (0.05/(2*n)), n-2-1) # considering p'=2 (intercept and car_mileage), could be wrong -- double check
print(threshold)
studentized_residuals <- rstudent(model)
outlier_indices <- which(abs(studentized_residuals) > threshold)
clean_cm_data <- clean_cm_data[-outlier_indices, ]

#cleaning for horsepower
model <- lm(price ~ horsepower, data = clean_data)

# leverage points (outliers in x) removal
leverage <- hatvalues(model)
threshold <- 2 * length(coef(model)) / nrow(clean_data)
leverage_points <- which(leverage > threshold | leverage > 0.5)
clean_hp_data <- clean_data[-leverage_points, ]

#clean_hp_data <- subset(clean_data, price <= 60000) # trimming y-axis data, will cause bias. 

# outliers in y removal
n <- nrow(clean_data)
print(n)
threshold <- qt(1 - (0.05/(2*n)), n-2-1) # considering p'=2 (intercept and horsepower), could be wrong -- double check
print(threshold)
studentized_residuals <- rstudent(model)
outlier_indices <- which(abs(studentized_residuals) > threshold)
clean_hp_data <- clean_hp_data[-outlier_indices, ]

# TO DO: (?) should we repeat this process for the other continuous variables? 

ggplot(clean_cm_data, aes(x = car_mileage, y = price)) + geom_point() + theme_minimal() + ggtitle("car_mileage vs price") 
ggplot(clean_hp_data, aes(x = horsepower, y = price)) + geom_point() + theme_minimal() + ggtitle("horsepower vs price") 
```

After outlier cleaning, let's check on the scatter plots again to see if these continuous variables have a significant influence on the car price:

```{R}
p1 <- ggplot(clean_data, aes(x = age, y = price)) + geom_point() + geom_smooth(method = "lm", se = TRUE, color = "blue") + theme_minimal() + ggtitle("age vs price")
p2 <- ggplot(clean_hp_data, aes(x = horsepower, y = price)) + geom_point() + geom_smooth(method = "lm", se = TRUE, color = "blue") + theme_minimal() + ggtitle("horsepower vs price")
p3 <- ggplot(clean_cm_data, aes(x = car_mileage, y = price)) + geom_point() + geom_smooth(method = "lm", se = TRUE, color = "blue") + theme_minimal() + ggtitle("car_mileage vs price") # needs outlier removed
p4 <- ggplot(clean_data, aes(x = engine_capacity, y = price)) + geom_point() + geom_smooth(method = "lm", se = TRUE, color = "blue") + theme_minimal() + ggtitle("engine_capacity vs price")
grid.arrange(p1,p2,p3,p4,ncol=2)
```

[note: minor concern... if you look at the p-value and t-value for car_mileage, you'll notice that we fail to rejct H_0: beta_1=0 for it...? does this mean we should exclude it...?]

```{R}
model <- lm(price ~ age, data = clean_data)
summary(model)
model <- lm(price ~ horsepower, data = clean_data)
summary(model)
model <- lm(price ~ car_mileage, data = clean_data)
summary(model)
model <- lm(price ~ engine_capacity, data = clean_data)
summary(model)
```

Now moving on to the categorical variables.

[TO DO: There's some weird charts that the exemplar from last yr uses. If anyone can figure out how to make and interpret those that'd be great.]

We need to make sure that there's no correlation between the different categorical variables.

```{R}
# Select numeric predictors only
numeric_data <- clean_data[sapply(clean_data, is.numeric)]

# Remove specific variables like 'Year'
numeric_data <- numeric_data[, !names(numeric_data) %in% c("year")]

# Compute correlation matrix
cor_matrix <- cor(numeric_data, use = "complete.obs")

# Plot correlation matrix with ggcorrplot
ggcorrplot(
  cor_matrix, 
  method = "square",       # Style of the plot
  type = "lower",          # Show lower triangular correlation matrix
  lab = TRUE,              # Display correlation values inside the cells
  lab_size = 3,            # Adjust size of labels
  title = "Correlation Heatmap",  # Add a title
  colors = c("blue", "white", "red") # Define color gradient (negative, neutral, positive correlations)
)
```

[Note: based off of this correlation map: - Remove one of views/favourites since this has strong correlation (but I think we're getting rid of both anyways) - Ensure no multicollinearity between horsepower and engine_capacity (VIF?) - Check to see if we can remove seats_amount and car_mileage from the model since they don't give much information on price it looks like - this is just a little suspicious since usually more mileage should mean cheaper car? just make sure to do lots of investigation before removing it.]

Before we delve further into data analysis, we notice that there's some information in our dataset that is unlikely to be relevant, such as how many views or favourites the car posting gets, or the date of which it was posted. However, we need to run a t-test to make sure that those variables indeed do not have any influence on the final price of the car.

[TO DO: - get rid of certain variables like Views etc., justify using math/stats (can't just say "pretty sure it won't affect anything") - pretty sure it's just a basic beta_i = 0 t-test? correct me if I'm wrong]


## Categorical Vairable Analysis

```{r}
# List of all categorical variables
categorical_vars <- c("post_info", "A_C", "emission_class", "seats_amount", 
                      "color", "type_of_drive", "doors", "fuel", 
                      "car_type", "gearbox")

# Create individual plots for each categorical variable
for (var in categorical_vars) {
  
  # Filter non-empty data for the current variable
  non_empty_data <- clean_data[!is.na(clean_data[[var]]) & !is.na(clean_data$price), ]

  # Check if the variable is a factor; if not, convert it
  if (!is.factor(non_empty_data[[var]])) {
    non_empty_data[[var]] <- as.factor(non_empty_data[[var]])
  }
  
  # Create the violin + box plot
  plot <- ggplot(non_empty_data, aes(x = .data[[var]], y = price)) +
    geom_violin(fill = "blue", alpha = 0.5) +
    geom_boxplot(width = 0.1, fill = "white", outlier.size = 0.5) +
    labs(title = paste("Price vs", var), y = "Price", x = "") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
    print(plot)
}


```


[from here on is a load of garbage :( if you think you can help fix it, you're more than welcome. Though, it might be easier to just use this as code reference

-Rebecca]

## Outlier Detection

[TO DO, pretty sure outliers are causing some of these other tests to look weird or become incomprehensible?]

Removing Leverage Points (outliers along X-axis):

Removing outliers along Y-axis:

Removing Influential Points:

## Data Analysis

[TO DO, need to analyse the variables by themselves - The violin plots are NOT what we want to see. Either they'll fix themselves after we remove outliers or we have to do something else]

Now, we want to take a look at the distributions of our data, to see if there are any peculiarities that we should be aware of. For continuous data: **age**, **horsepower**, **car mileage**, and **engine capacity**, we examine their violin plots:

```{r}
non_empty_age <- clean_data[!is.na(clean_data$age) & !is.na(clean_data$age), ]

age_graph <- ggplot(non_empty_age, aes(x = "", y = age)) +
  geom_violin(fill = "purple", alpha = 0.5, trim=TRUE) +  
  geom_boxplot(width = 0.1, alpha = 0.8) +    
  labs(title = "Age Distribution", y = "Age", x = "")

non_empty_hp <- data.frame(horsepower = as.integer(clean_data$horsepower[clean_data$horsepower != ""]))

horsepower_graph <- ggplot(non_empty_hp, aes(x = "", y = horsepower)) +
  geom_violin(fill = "blue", alpha = 0.5) +
  geom_boxplot(width = 0.1, fill = "white", outlier.size = 0.5) +
  labs(title = "Horsepower Distribution", y = "Horsepower", x = "")

non_empty_cm <- data.frame(car_mileage = as.integer(clean_data$car_mileage[clean_data$car_mileage != ""]))

# Plot for "car_mileage"
car_mileage_graph <- ggplot(clean_data, aes(x = "", y = car_mileage)) +
  geom_violin(fill = "green", alpha = 0.5) +
  geom_boxplot(width = 0.1, fill = "white", outlier.size = 0.5) +
  labs(title = "Car Mileage Distribution", y = "Mileage", x = "")

non_empty_ec <- data.frame(engine_capacity = as.integer(clean_data$engine_capacity[clean_data$engine_capacity != ""]))

# Plot for "engine_capacity"
engine_capacity_graph <- ggplot(clean_data, aes(x = "", y = engine_capacity)) +
  geom_violin(fill = "orange", alpha = 0.5) +
  geom_boxplot(width = 0.1, fill = "white", outlier.size = 0.5) +
  labs(title = "Engine Capacity Distribution", y = "Capacity", x = "")

all_plots <- age_graph + horsepower_graph + car_mileage_graph + engine_capacity_graph + plot_layout(ncol = 2) 
print(all_plots)
```

## Correlation Analysis

[Note from Rebecca (last person to work on this): this is a little broken right now.

-   need to modify the correlation chart to get rid of some useless variables like views
-   heatmap is not working I think bc there's a bunch of outliers in dataset. Going to clean out outliers first, then I'll get back to heatmap ]

```{r}

numeric_data <- clean_data[sapply(clean_data, is.numeric)]
cor_matrix <- cor(numeric_data, use = "complete.obs")

ggcorrplot(
  cor_matrix, 
  method = "square", 
  type = "lower",  
  lab = TRUE,      
  title = "Correlation Heatmap",
  colors = c("blue", "white", "red") 
)

clean_data$log_horsepower <- log10(as.integer(clean_data$horsepower))
clean_data$log_car_mileage <- log10(as.integer(clean_data$car_mileage))

ggplot(clean_data, aes(x = log_horsepower, y = log_car_mileage)) +
  geom_bin2d(binwidth = c(10, 500)) +  # Adjust bin width for better visualization
  scale_fill_gradient(low = "blue", high = "yellow") +  # Density color scale
  labs(title = "Density of Horsepower vs. Car Mileage",
       x = "Horsepower", y = "Car Mileage", fill = "Count") +
  theme_minimal()
```
